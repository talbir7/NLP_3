{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de BertScrapping.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2QNx8Cq_GSNM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b81953b51684c3385d1e9e8fe856368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55b2ee8bd53e41498aeb90f3b2b8d070",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8144c86b427f433bb677792d72cffee9",
              "IPY_MODEL_134b4c4f33434af2848f19420f6a98ce"
            ]
          }
        },
        "55b2ee8bd53e41498aeb90f3b2b8d070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8144c86b427f433bb677792d72cffee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0a899c6c25c4a55935ee23b304a1d32",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 443,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 443,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66d72628c4dd4d05bcef18b798733c9b"
          }
        },
        "134b4c4f33434af2848f19420f6a98ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_103a3d9ce0ab45f8826d27fe0fd1cf70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443/443 [00:00&lt;00:00, 711B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c577424951c4db6ba0d124cfcbcb2b6"
          }
        },
        "e0a899c6c25c4a55935ee23b304a1d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66d72628c4dd4d05bcef18b798733c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "103a3d9ce0ab45f8826d27fe0fd1cf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c577424951c4db6ba0d124cfcbcb2b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14907a1b2e3149a6ac2587b5e16c0c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3b5513784ef4cdca049c402d1fd437d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7e5d782dfe241689afe4750f63e0979",
              "IPY_MODEL_36d4404b9e05493d8b56874c6fbd3f2a"
            ]
          }
        },
        "c3b5513784ef4cdca049c402d1fd437d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7e5d782dfe241689afe4750f63e0979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e19c6d371a2497d9b8e6bf4aba8a405",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1340675298,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1340675298,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8d7f2a050fc4e619db073c9b571b4c6"
          }
        },
        "36d4404b9e05493d8b56874c6fbd3f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_393564ff309c40cf8dce7254e29c57a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:40&lt;00:00, 32.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8edb0567ea6e4956a7c958786e98822f"
          }
        },
        "5e19c6d371a2497d9b8e6bf4aba8a405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8d7f2a050fc4e619db073c9b571b4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "393564ff309c40cf8dce7254e29c57a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8edb0567ea6e4956a7c958786e98822f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d0e1c865fd24a69af2e8aa5e8050ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3162846466684766bf6a408c869e15b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26bd67e6cdce400ea08f4db37f8bc284",
              "IPY_MODEL_f4a4ca4a42224e8c8c775e79e94bcd58"
            ]
          }
        },
        "3162846466684766bf6a408c869e15b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26bd67e6cdce400ea08f4db37f8bc284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b74cbecdb89a4757a0c386274dfa4a48",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_995a6740091642e19cc1ffa237ee4c71"
          }
        },
        "f4a4ca4a42224e8c8c775e79e94bcd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6cfad08028f64dcbbe8c23e23f56c1ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.36MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e76c68f9bd147b895c5c5e8514bea5b"
          }
        },
        "b74cbecdb89a4757a0c386274dfa4a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "995a6740091642e19cc1ffa237ee4c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cfad08028f64dcbbe8c23e23f56c1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e76c68f9bd147b895c5c5e8514bea5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZItw6aDq8yy"
      },
      "source": [
        "#RÃ©alisÃ© par :\n",
        "\n",
        "\n",
        "*   Rayhane Talbi\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#Outils :\n",
        "* Google collab\n",
        "* Python3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEkasyqIQtL2"
      },
      "source": [
        "# **Librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucjR_xuoozKY",
        "outputId": "75aed178-3b00-4394-93e2-6ce37427c581"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 17.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=97263d2528f8a6a7a61a22df5a38d951b8875c1c1a511511afb903ea08042fb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdonWItpo-zM",
        "outputId": "f4c5c4e9-d3cc-4a0f-c7ae-677bfcfeec38"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPGxGCbOpBZm"
      },
      "source": [
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi2VTOp5Q3AF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuGMbLz-R2tn"
      },
      "source": [
        "# **Web Scrapping**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBnj8jgIBbj"
      },
      "source": [
        "Afin de disposer d'un nombre de questions necessaires, nous avons dÃ©cidÃ© de travailler sur 3 sites diffÃ©rents. L'avantage est que nous obtenons alors un grand nombre de questions diverses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2IPcXcp2P5j"
      },
      "source": [
        "## **SITE 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_c3yQ63WpmS"
      },
      "source": [
        "# user agent d'un navigateur moderne pour les requetes\n",
        "header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.80 Safari/537.36'}\n",
        "\n",
        "# URL du premier site\n",
        "URL = 'https://onlinecoursetutorials.com/interview-questions/natural-language-processing-interview-questions-and-answers/'\n",
        "\n",
        "httpx = requests.get(URL, headers=header)\n",
        "soup = BeautifulSoup(httpx.text, 'html.parser')\n",
        "\n",
        "# RÃ©cupÃ¨re les elements de la classe the_content\n",
        "questionsSoup = soup.find(class_='the_content')\n",
        "\n",
        "# L'ensemble des questions se trouvent dans tr\n",
        "questionsSoup_tr = questionsSoup.find_all('tr')\n",
        "df = pd.DataFrame(columns=['Question', 'Answer'], index = np.arange(200))\n",
        "cpt_ligne = 0\n",
        "cpt_df = 0\n",
        "for question_answer in questionsSoup_tr:\n",
        "  # Remove \\n\n",
        "  tmp = question_answer.get_text().replace(\"\\n\", \"\")\n",
        "  # This question has no answer\n",
        "  if( \"What are punctuationâ€™s ? How can you remove it ?\" not in tmp):\n",
        "    if(tmp != \"\"):\n",
        "      # Alternance de question et rÃ©ponse\n",
        "      if(cpt_ligne%2==0 and (\"What\" in tmp or \"?\" in tmp)):\n",
        "        df['Question'].loc[cpt_df] = tmp\n",
        "        cpt_ligne = 0\n",
        "      else:\n",
        "        if(cpt_ligne%2 ==0):\n",
        "          tmp2 = df['Answer'].loc[cpt_df-1]\n",
        "          df['Answer'].loc[cpt_df-1] = tmp + \"-\" + tmp2\n",
        "          cpt_ligne = 1\n",
        "        else:\n",
        "          df['Answer'].loc[cpt_df] = tmp \n",
        "          cpt_df = cpt_df + 1\n",
        "          cpt_ligne = 1\n",
        "      cpt_ligne = cpt_ligne + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2WOOBjhzjH7"
      },
      "source": [
        "## **SITE 2**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iM2CuVe53KQ"
      },
      "source": [
        "# URL du second site\n",
        "URL = 'https://www.wisdomjobs.com/e-university/natural-language-processing-interview-questions.html'\n",
        "\n",
        "httpx = requests.get(URL, headers=header)\n",
        "soup = BeautifulSoup(httpx.text, 'html.parser')\n",
        "#print(BeautifulSoup(httpx.content, 'html'))\n",
        "questionsSoup = soup.find(class_='interview_questions')\n",
        "questionsSoup = questionsSoup.get_text().split('\\n')\n",
        "questionsSoup = [e for e in questionsSoup if(e.strip()!='' and \"adsbygoogle\" not in e and \"Python\" not in e and 'Tutorial' not in e and 'Interview' not in e)]\n",
        "\n",
        "for q in questionsSoup:\n",
        "  if 'Question' in q and 'Answer' not in q:\n",
        "    cpt_df += 1\n",
        "    df['Question'].loc[cpt_df] = q\n",
        "  else:\n",
        "    if(str( df['Answer'].loc[cpt_df])!= \"nan\"):\n",
        "      tmp2 = df['Answer'].loc[cpt_df]\n",
        "      df['Answer'].loc[cpt_df] = q + \"-\" + tmp2\n",
        "    else:\n",
        "      df['Answer'].loc[cpt_df] = q "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QNx8Cq_GSNM"
      },
      "source": [
        "## **Site 3**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx3bv_3wIcV9"
      },
      "source": [
        "Le webscraping pour ce site est bien plus compliquÃ© que les deux derniers, mais il nous a fournit un nombre de questions et une diversitÃ© non nÃ©gligeable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtfPdcobElXV"
      },
      "source": [
        "# URL du troisiÃ¨me site\n",
        "URL3 = 'https://www.mygreatlearning.com/blog/nlp-interview-questions/'\n",
        "\n",
        "httpx3 = requests.get(URL3, headers=header)\n",
        "soup3 = BeautifulSoup(httpx3.text, 'html.parser')\n",
        "#print(BeautifulSoup(httpx.content, 'html'))\n",
        "questionsSoup3 = soup3.find(class_='td-post-content')\n",
        "\n",
        "paragraphQSoup = questionsSoup3.find_all('p') # Paragraphe avec les questions et reponsent\n",
        "listParag = list()\n",
        "for i in paragraphQSoup:\n",
        "  tmp = i.get_text().strip() # Convertion sous forme de text et efface les espaces\n",
        "  listParag.append(re.split(r'r\\d{1}', tmp)) # Split les elements par format de la question (1. 2. ...)\n",
        "\n",
        "# Les 2 premiÃ¨res lignes ne reprÃ©sentent pas des QA et les elements suivant doivent Ãªtre prÃ©parÃ©s pour Ãªtre modifiÃ©s\n",
        "td = listParag[2:28] # PremiÃ¨re partie\n",
        "# QA contient des questions et rÃ©ponses au format correct Question puis rÃ©ponse alternÃ©e\n",
        "QA = listParag[28:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj5qU1yY_6uu"
      },
      "source": [
        "# Seconde partie\n",
        "# Ici on ne va travailler que sur les elements de la liste de questions au mauvais format\n",
        "# Convertit la liste de liste en liste\n",
        "flat_list = [item for sublist in td for item in sublist]\n",
        "# Convertit la liste en chaine de caractere \n",
        "s = \"\"\n",
        "for i in flat_list:\n",
        "  s = s + i\n",
        "\n",
        "l = list(range(1, 39))\n",
        "l = [str(e) + \".\" for e in l]\n",
        "listQA = list()\n",
        "# On split les elements de la liste par numÃ©ro de question\n",
        "for i in reversed(l):\n",
        "  listQA.append(s.split(i)[1:])\n",
        "\n",
        "# On ajoute le numÃ©ro de question aux questions correctement split\n",
        "cpt = 0\n",
        "QA_better = list()\n",
        "for i in reversed(listQA):\n",
        "  if (len(i) ==1):\n",
        "    QA_better.append(l[cpt] + i[0])\n",
        "  cpt =  cpt + 1\n",
        "\n",
        "# On efface pour chaque question les questions suivantes\n",
        "cpt = 10\n",
        "for i in range(len(QA_better)-2):\n",
        "  tmp = QA_better[i+1].replace(l[cpt+1], \"\")\n",
        "  QA_better[i] =  QA_better[i].replace(QA_better[i+1], \"\")\n",
        "\n",
        "# On split chaque quest\n",
        "list_QA_split = list()\n",
        "for i in QA_better:\n",
        "  list_QA_split.append(i.split(\"Ans\"))\n",
        "  if(len(i.split(\"Ans \"))> 2):\n",
        "    print(\"ALAID\")\n",
        "list_QA_split\n",
        "flat_list = [item for sublist in list_QA_split for item in sublist]\n",
        "# Contient les questions 10 Ã  38, alterne question et reponse\n",
        "\n",
        "tmp  = flat_list + [item for sublist in QA for item in sublist]\n",
        "ls = list(range(10,50))\n",
        "indice_question = 0\n",
        "for i in range(len(tmp)-1):\n",
        "  if(indice_question%2 == 0):\n",
        "    # C'est une question et doit donc contenir un nombre\n",
        "    if(str(ls[indice_question]) not in tmp[i]):\n",
        "      # Alors c'est une rÃ©ponse \n",
        "      print(ls[indice_question])\n",
        "      print(tmp[i])\n",
        "      tmp[i-1] = tmp[i-1] + \" \" +  tmp[i]\n",
        "      tmp[i] =\"\"\n",
        "    else:\n",
        "      indice_question = indice_question + 1\n",
        "  else:\n",
        "    # C'est une rÃ©ponse\n",
        "    # RecupÃ¨re la valeur de la rÃ©ponse dans la question\n",
        "    if( \"a)\" in tmp[i]):\n",
        "      first = tmp[i-1].split('a.')\n",
        "      second = first[-1].split('b.')\n",
        "      tmp[i] = tmp[i].replace(\"a)\", \"a)\" + second[0]+ \" \")    \n",
        "    elif( 'b)' in tmp[i]):\n",
        "      first = tmp[i-1].split('b.')\n",
        "      second = first[-1].split('c.')\n",
        "      tmp[i] = tmp[i].replace(\"b)\", \"b)\" + second[0]+ \" \")\n",
        "    elif( 'c)' in tmp[i]):\n",
        "      first = tmp[i-1].split('c.')\n",
        "      second = first[-1].split('d.')\n",
        "      tmp[i] = tmp[i].replace(\"c)\", \"c)\" + second[0]+ \" \")   \n",
        "    elif( 'd)' in tmp[i]):\n",
        "      first = tmp[i-1].split('d.')\n",
        "      second = first[-1]\n",
        "      tmp[i] = tmp[i].replace(\"d)\", \"d)\" + second+ \" \")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4FAbtQvanF5"
      },
      "source": [
        "# Insertion des questions rÃ©ponses dans le dataframe\n",
        "# Seconde partie des questions\n",
        "cpt_df += 1\n",
        "for i in tmp:\n",
        "  try:\n",
        "    int(i[0])\n",
        "    cpt_df += 1\n",
        "    df['Question'].loc[cpt_df] = i\n",
        "  except:\n",
        "    df['Answer'].loc[cpt_df] = i\n",
        "\n",
        "# PremiÃ¨re partie\n",
        "cpt_df += 1\n",
        "reponse=\"\"\n",
        "for l in range(len(QA)):\n",
        "  question=\"\"\n",
        "  try: \n",
        "    int(QA[l][0][0])\n",
        "  #Si Ã§a ne commence pas par un numÃ©ro c'est une rÃ©ponse\n",
        "  except:\n",
        "    reponse+=QA[l][0]\n",
        "    \n",
        "  else:\n",
        "    if (l != 0):\n",
        "      df['Answer'].loc[cpt_df] = reponse\n",
        "      reponse=\"\"\n",
        "    cpt_df += 1\n",
        "    question = QA[l][0].split('.')[1:]\n",
        "    q = question[0]\n",
        "    df['Question'].loc[cpt_df] = q\n",
        "\n",
        "df['Answer'].loc[cpt_df] = reponse\n",
        "\n",
        "# Efface les cellules vides - allocation Ã  200\n",
        "df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqrS1MEm-Ugm"
      },
      "source": [
        "On obtient un dataframe composÃ© des questions et rÃ©ponses de 3 diffÃ©rents sites. Il n'est pas nÃ©cÃ©ssaire de prÃ©process le texte puisque Bert s'en chargera par la suite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH7Hao_qSLXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7476e039-a5ad-4032-ca00-7db52a0cd041"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is NLP(natural language processing) ?</td>\n",
              "      <td>Natural language processing is a subfield of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is applications of NLP ?</td>\n",
              "      <td>Text classification, Text summarization, Name ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is tokenization ?</td>\n",
              "      <td>Splitting the sentence into words</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is stemming ?</td>\n",
              "      <td>Stemming is the process of reducing a word to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is lemmatizing ?</td>\n",
              "      <td>Lemmatizing is also same like stemming but the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Which NLP model gives best accuracy?</td>\n",
              "      <td>Naive Bayes Algorithm has the highest accuracy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>What are the major tasks of NLP?</td>\n",
              "      <td>Translation, named entity recognition, relatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>What are stop words in NLP?</td>\n",
              "      <td>Common words that occur in sentences that add ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>What is stemming in NLP?</td>\n",
              "      <td>The process of obtaining the root word from th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>Why is NLP so hard?</td>\n",
              "      <td>There are several factors that make the proces...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Question                                             Answer\n",
              "0    What is NLP(natural language processing) ?  Natural language processing is a subfield of c...\n",
              "1                 What is applications of NLP ?  Text classification, Text summarization, Name ...\n",
              "2                        What is tokenization ?                  Splitting the sentence into words\n",
              "3                           What is stemming ?Â   Stemming is the process of reducing a word to ...\n",
              "4                        What is lemmatizing ?Â   Lemmatizing is also same like stemming but the...\n",
              "..                                          ...                                                ...\n",
              "114        Which NLP model gives best accuracy?  Naive Bayes Algorithm has the highest accuracy...\n",
              "115            What are the major tasks of NLP?  Translation, named entity recognition, relatio...\n",
              "116                 What are stop words in NLP?  Common words that occur in sentences that add ...\n",
              "117                    What is stemming in NLP?  The process of obtaining the root word from th...\n",
              "118                         Why is NLP so hard?  There are several factors that make the proces...\n",
              "\n",
              "[115 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCvdT4CYV2UZ"
      },
      "source": [
        "## **Trie**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIji-wMXLGui"
      },
      "source": [
        "# Trie le dataframe dans l'ordre croissant de la taille des questions \n",
        "s = df.Answer.str.len().sort_values().index # Renvoie les indexes\n",
        "ds = df.reindex(s) # RecupÃ¨re les indexes \n",
        "ds  = ds.reset_index() # Reset les indexes\n",
        "df = ds[:81] # RecupÃ¨re une questions ayant les rÃ©ponses les plus courtes pour un fonctionnement optimal de Bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CizCe4vkUliL"
      },
      "source": [
        "# **Bert**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u73fWkr6Umec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "2b81953b51684c3385d1e9e8fe856368",
            "55b2ee8bd53e41498aeb90f3b2b8d070",
            "8144c86b427f433bb677792d72cffee9",
            "134b4c4f33434af2848f19420f6a98ce",
            "e0a899c6c25c4a55935ee23b304a1d32",
            "66d72628c4dd4d05bcef18b798733c9b",
            "103a3d9ce0ab45f8826d27fe0fd1cf70",
            "5c577424951c4db6ba0d124cfcbcb2b6",
            "14907a1b2e3149a6ac2587b5e16c0c14",
            "c3b5513784ef4cdca049c402d1fd437d",
            "f7e5d782dfe241689afe4750f63e0979",
            "36d4404b9e05493d8b56874c6fbd3f2a",
            "5e19c6d371a2497d9b8e6bf4aba8a405",
            "f8d7f2a050fc4e619db073c9b571b4c6",
            "393564ff309c40cf8dce7254e29c57a4",
            "8edb0567ea6e4956a7c958786e98822f",
            "2d0e1c865fd24a69af2e8aa5e8050ae4",
            "3162846466684766bf6a408c869e15b9",
            "26bd67e6cdce400ea08f4db37f8bc284",
            "f4a4ca4a42224e8c8c775e79e94bcd58",
            "b74cbecdb89a4757a0c386274dfa4a48",
            "995a6740091642e19cc1ffa237ee4c71",
            "6cfad08028f64dcbbe8c23e23f56c1ee",
            "5e76c68f9bd147b895c5c5e8514bea5b"
          ]
        },
        "outputId": "94134058-83d4-4de7-da25-dffd6e7baa8d"
      },
      "source": [
        "#Model\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "\n",
        "#Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b81953b51684c3385d1e9e8fe856368",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14907a1b2e3149a6ac2587b5e16c0c14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d0e1c865fd24a69af2e8aa5e8050ae4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZDqUZ2GUpIn"
      },
      "source": [
        "#fonction permettant l'application de bert sur une question et une chaine de caractÃ¨re contenant les rÃ©ponses \n",
        "def bert(question,reponse):\n",
        "  encoding = tokenizer.encode_plus(text=question,text_pair=reponse, add_special=True)\n",
        "\n",
        "  inputs = encoding['input_ids']  #Token embeddings\n",
        "  sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
        "  tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
        "\n",
        "  x=model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
        "  start_index = torch.argmax(x[0])\n",
        "\n",
        "  end_index = torch.argmax(x[1])\n",
        "\n",
        "  answer = ' '.join(tokens[start_index:end_index+1])\n",
        "  \n",
        "  corrected_answer = ''\n",
        "\n",
        "  for word in answer.split():\n",
        "      \n",
        "      #If it's a subword token\n",
        "      if word[0:2] == '##':\n",
        "          corrected_answer += word[2:]\n",
        "      else:\n",
        "          corrected_answer += ' ' + word\n",
        "  return corrected_answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyEzLoTKrfGN"
      },
      "source": [
        "Pour utiliser Bert, on doit donner a notre modÃ¨le une question et une chaine de caractÃ¨re contenant les rÃ©ponses aux potentielles questions.\n",
        "\n",
        "Cepandant, Bert limite la quantitÃ© max de tokens de la liste de rÃ©ponses Ã  512, nous empÃªchant de l'utiliser directement sur toutes nos rÃ©ponses. On doit rÃ©aliser l'algorithme de Bert sur plusieurs subsets de rÃ©ponses, plutÃ´t que sur l'ensemble. \n",
        "\n",
        "On considÃ©rera par la suite l'ensemble des rÃ©ponses retournÃ©es par Bert comme nouvel ensemble de rÃ©ponses possible a notre question. On rÃ©alisera cette opÃ©ration tant que la liste de rÃ©ponses pottentielles est trop grande pour Bert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq1HPWPcpPwK"
      },
      "source": [
        "#fonction permettant de diviser la listes de rÃ©ponse via Bert en sous listes de tailles sufisament petites pour appliquer Bert dessus\n",
        "def reduc(reponseBertamodif):\n",
        "  i=0\n",
        "  reponses=[]\n",
        "  answer=''\n",
        "  while (i<len(reponseBertamodif)):\n",
        "    if (len(answer)<300 and ( len(reponseBertamodif[i]) + len(answer))<300 ):\n",
        "      try:\n",
        "        answer+=reponseBertamodif[i]\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    else:\n",
        "      reponses.append(answer)\n",
        "      answer=''\n",
        "      i-=1\n",
        "    i+=1\n",
        "    \n",
        "  return reponses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqvmV-UiYpQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e190ff9f-1f46-4269-9562-481f7e1b01c2"
      },
      "source": [
        "#Question Ã  poser a notre algorithme :\n",
        "question = 'What is NLP '\n",
        "\n",
        "#On extrait les rÃ©ponses du dataframe, que l'on enregistre sous forme de liste\n",
        "i=0\n",
        "reponses=[]\n",
        "answer=''\n",
        "while (i<len(df)):\n",
        "  if (len(answer)<300 and ( len(df['Answer'][i]) + len(answer))<300 ):\n",
        "    try:\n",
        "      answer+=df['Answer'][i]\n",
        "    except:\n",
        "      pass\n",
        "  else:\n",
        "    reponses.append(answer)\n",
        "    answer=''\n",
        "    i-=1\n",
        "  i+=1\n",
        "  \n",
        "#On obtient la variable reponse qui contient une liste de rÃ©ponses de taille suffisament petite pour Bert\n",
        "#On rÃ©alise Bert sur toutes les sous listes de rÃ©ponses\n",
        "reponseBert =''\n",
        "reponseBertTableau=[]\n",
        "for i in range(len(reponses)):\n",
        "  result = bert(question,reponses[i])+'.'\n",
        "  reponseBertTableau.append(result)\n",
        "  reponseBert+=result\n",
        "\n",
        "\n",
        "vermines = ['','.',',']\n",
        "#Tant que les diffÃ©rentes rÃ©ponses via bert on une taille trop Ã©levÃ© pour utiliser l'algorithme une seule fois,\n",
        "#On redivise nos rÃ©ponses en listes de rÃ©ponses\n",
        "while len(reponseBert)>300 :\n",
        "  reponses = reduc(reponseBertTableau)\n",
        "  tmp=[]\n",
        "  reponseBert=''\n",
        "  for i in range(len(reponses)):\n",
        "    if (reponses[i] not in vermines):\n",
        "      result=bert(question,reponses[i])+'.'\n",
        "      reponseBert+=result\n",
        "      tmp.append(result)\n",
        "  reponseBertTableau=tmp\n",
        "\n",
        "finalAnswer = bert(question,reponseBert)\n",
        "print(question)\n",
        "print(finalAnswer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "What is NLP \n",
            " natural language processing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Y-mKFmisUqku",
        "outputId": "854ab398-5056-4c9e-9a86-31980f53588c"
      },
      "source": [
        "finalAnswer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' natural language processing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}