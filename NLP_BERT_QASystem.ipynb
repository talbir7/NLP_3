{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de BertScrapping.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2QNx8Cq_GSNM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b81953b51684c3385d1e9e8fe856368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55b2ee8bd53e41498aeb90f3b2b8d070",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8144c86b427f433bb677792d72cffee9",
              "IPY_MODEL_134b4c4f33434af2848f19420f6a98ce"
            ]
          }
        },
        "55b2ee8bd53e41498aeb90f3b2b8d070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8144c86b427f433bb677792d72cffee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0a899c6c25c4a55935ee23b304a1d32",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 443,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 443,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66d72628c4dd4d05bcef18b798733c9b"
          }
        },
        "134b4c4f33434af2848f19420f6a98ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_103a3d9ce0ab45f8826d27fe0fd1cf70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443/443 [00:00&lt;00:00, 711B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c577424951c4db6ba0d124cfcbcb2b6"
          }
        },
        "e0a899c6c25c4a55935ee23b304a1d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66d72628c4dd4d05bcef18b798733c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "103a3d9ce0ab45f8826d27fe0fd1cf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c577424951c4db6ba0d124cfcbcb2b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14907a1b2e3149a6ac2587b5e16c0c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3b5513784ef4cdca049c402d1fd437d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7e5d782dfe241689afe4750f63e0979",
              "IPY_MODEL_36d4404b9e05493d8b56874c6fbd3f2a"
            ]
          }
        },
        "c3b5513784ef4cdca049c402d1fd437d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7e5d782dfe241689afe4750f63e0979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5e19c6d371a2497d9b8e6bf4aba8a405",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1340675298,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1340675298,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8d7f2a050fc4e619db073c9b571b4c6"
          }
        },
        "36d4404b9e05493d8b56874c6fbd3f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_393564ff309c40cf8dce7254e29c57a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:40&lt;00:00, 32.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8edb0567ea6e4956a7c958786e98822f"
          }
        },
        "5e19c6d371a2497d9b8e6bf4aba8a405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8d7f2a050fc4e619db073c9b571b4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "393564ff309c40cf8dce7254e29c57a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8edb0567ea6e4956a7c958786e98822f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d0e1c865fd24a69af2e8aa5e8050ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3162846466684766bf6a408c869e15b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26bd67e6cdce400ea08f4db37f8bc284",
              "IPY_MODEL_f4a4ca4a42224e8c8c775e79e94bcd58"
            ]
          }
        },
        "3162846466684766bf6a408c869e15b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26bd67e6cdce400ea08f4db37f8bc284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b74cbecdb89a4757a0c386274dfa4a48",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_995a6740091642e19cc1ffa237ee4c71"
          }
        },
        "f4a4ca4a42224e8c8c775e79e94bcd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6cfad08028f64dcbbe8c23e23f56c1ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.36MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e76c68f9bd147b895c5c5e8514bea5b"
          }
        },
        "b74cbecdb89a4757a0c386274dfa4a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "995a6740091642e19cc1ffa237ee4c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cfad08028f64dcbbe8c23e23f56c1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e76c68f9bd147b895c5c5e8514bea5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZItw6aDq8yy"
      },
      "source": [
        "#Réalisé par :\n",
        "\n",
        "\n",
        "*   Rayhane Talbi\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#Outils :\n",
        "* Google collab\n",
        "* Python3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEkasyqIQtL2"
      },
      "source": [
        "# **Librairies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucjR_xuoozKY",
        "outputId": "75aed178-3b00-4394-93e2-6ce37427c581"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 17.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=97263d2528f8a6a7a61a22df5a38d951b8875c1c1a511511afb903ea08042fb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdonWItpo-zM",
        "outputId": "f4c5c4e9-d3cc-4a0f-c7ae-677bfcfeec38"
      },
      "source": [
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPGxGCbOpBZm"
      },
      "source": [
        "import torch\n",
        "from transformers import BertForQuestionAnswering\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qi2VTOp5Q3AF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuGMbLz-R2tn"
      },
      "source": [
        "# **Web Scrapping**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBnj8jgIBbj"
      },
      "source": [
        "Afin de disposer d'un nombre de questions necessaires, nous avons décidé de travailler sur 3 sites différents. L'avantage est que nous obtenons alors un grand nombre de questions diverses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2IPcXcp2P5j"
      },
      "source": [
        "## **SITE 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_c3yQ63WpmS"
      },
      "source": [
        "# user agent d'un navigateur moderne pour les requetes\n",
        "header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.80 Safari/537.36'}\n",
        "\n",
        "# URL du premier site\n",
        "URL = 'https://onlinecoursetutorials.com/interview-questions/natural-language-processing-interview-questions-and-answers/'\n",
        "\n",
        "httpx = requests.get(URL, headers=header)\n",
        "soup = BeautifulSoup(httpx.text, 'html.parser')\n",
        "\n",
        "# Récupère les elements de la classe the_content\n",
        "questionsSoup = soup.find(class_='the_content')\n",
        "\n",
        "# L'ensemble des questions se trouvent dans tr\n",
        "questionsSoup_tr = questionsSoup.find_all('tr')\n",
        "df = pd.DataFrame(columns=['Question', 'Answer'], index = np.arange(200))\n",
        "cpt_ligne = 0\n",
        "cpt_df = 0\n",
        "for question_answer in questionsSoup_tr:\n",
        "  # Remove \\n\n",
        "  tmp = question_answer.get_text().replace(\"\\n\", \"\")\n",
        "  # This question has no answer\n",
        "  if( \"What are punctuation’s ? How can you remove it ?\" not in tmp):\n",
        "    if(tmp != \"\"):\n",
        "      # Alternance de question et réponse\n",
        "      if(cpt_ligne%2==0 and (\"What\" in tmp or \"?\" in tmp)):\n",
        "        df['Question'].loc[cpt_df] = tmp\n",
        "        cpt_ligne = 0\n",
        "      else:\n",
        "        if(cpt_ligne%2 ==0):\n",
        "          tmp2 = df['Answer'].loc[cpt_df-1]\n",
        "          df['Answer'].loc[cpt_df-1] = tmp + \"-\" + tmp2\n",
        "          cpt_ligne = 1\n",
        "        else:\n",
        "          df['Answer'].loc[cpt_df] = tmp \n",
        "          cpt_df = cpt_df + 1\n",
        "          cpt_ligne = 1\n",
        "      cpt_ligne = cpt_ligne + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2WOOBjhzjH7"
      },
      "source": [
        "## **SITE 2**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iM2CuVe53KQ"
      },
      "source": [
        "# URL du second site\n",
        "URL = 'https://www.wisdomjobs.com/e-university/natural-language-processing-interview-questions.html'\n",
        "\n",
        "httpx = requests.get(URL, headers=header)\n",
        "soup = BeautifulSoup(httpx.text, 'html.parser')\n",
        "#print(BeautifulSoup(httpx.content, 'html'))\n",
        "questionsSoup = soup.find(class_='interview_questions')\n",
        "questionsSoup = questionsSoup.get_text().split('\\n')\n",
        "questionsSoup = [e for e in questionsSoup if(e.strip()!='' and \"adsbygoogle\" not in e and \"Python\" not in e and 'Tutorial' not in e and 'Interview' not in e)]\n",
        "\n",
        "for q in questionsSoup:\n",
        "  if 'Question' in q and 'Answer' not in q:\n",
        "    cpt_df += 1\n",
        "    df['Question'].loc[cpt_df] = q\n",
        "  else:\n",
        "    if(str( df['Answer'].loc[cpt_df])!= \"nan\"):\n",
        "      tmp2 = df['Answer'].loc[cpt_df]\n",
        "      df['Answer'].loc[cpt_df] = q + \"-\" + tmp2\n",
        "    else:\n",
        "      df['Answer'].loc[cpt_df] = q "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QNx8Cq_GSNM"
      },
      "source": [
        "## **Site 3**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx3bv_3wIcV9"
      },
      "source": [
        "Le webscraping pour ce site est bien plus compliqué que les deux derniers, mais il nous a fournit un nombre de questions et une diversité non négligeable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtfPdcobElXV"
      },
      "source": [
        "# URL du troisième site\n",
        "URL3 = 'https://www.mygreatlearning.com/blog/nlp-interview-questions/'\n",
        "\n",
        "httpx3 = requests.get(URL3, headers=header)\n",
        "soup3 = BeautifulSoup(httpx3.text, 'html.parser')\n",
        "#print(BeautifulSoup(httpx.content, 'html'))\n",
        "questionsSoup3 = soup3.find(class_='td-post-content')\n",
        "\n",
        "paragraphQSoup = questionsSoup3.find_all('p') # Paragraphe avec les questions et reponsent\n",
        "listParag = list()\n",
        "for i in paragraphQSoup:\n",
        "  tmp = i.get_text().strip() # Convertion sous forme de text et efface les espaces\n",
        "  listParag.append(re.split(r'r\\d{1}', tmp)) # Split les elements par format de la question (1. 2. ...)\n",
        "\n",
        "# Les 2 premières lignes ne représentent pas des QA et les elements suivant doivent être préparés pour être modifiés\n",
        "td = listParag[2:28] # Première partie\n",
        "# QA contient des questions et réponses au format correct Question puis réponse alternée\n",
        "QA = listParag[28:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj5qU1yY_6uu"
      },
      "source": [
        "# Seconde partie\n",
        "# Ici on ne va travailler que sur les elements de la liste de questions au mauvais format\n",
        "# Convertit la liste de liste en liste\n",
        "flat_list = [item for sublist in td for item in sublist]\n",
        "# Convertit la liste en chaine de caractere \n",
        "s = \"\"\n",
        "for i in flat_list:\n",
        "  s = s + i\n",
        "\n",
        "l = list(range(1, 39))\n",
        "l = [str(e) + \".\" for e in l]\n",
        "listQA = list()\n",
        "# On split les elements de la liste par numéro de question\n",
        "for i in reversed(l):\n",
        "  listQA.append(s.split(i)[1:])\n",
        "\n",
        "# On ajoute le numéro de question aux questions correctement split\n",
        "cpt = 0\n",
        "QA_better = list()\n",
        "for i in reversed(listQA):\n",
        "  if (len(i) ==1):\n",
        "    QA_better.append(l[cpt] + i[0])\n",
        "  cpt =  cpt + 1\n",
        "\n",
        "# On efface pour chaque question les questions suivantes\n",
        "cpt = 10\n",
        "for i in range(len(QA_better)-2):\n",
        "  tmp = QA_better[i+1].replace(l[cpt+1], \"\")\n",
        "  QA_better[i] =  QA_better[i].replace(QA_better[i+1], \"\")\n",
        "\n",
        "# On split chaque quest\n",
        "list_QA_split = list()\n",
        "for i in QA_better:\n",
        "  list_QA_split.append(i.split(\"Ans\"))\n",
        "  if(len(i.split(\"Ans \"))> 2):\n",
        "    print(\"ALAID\")\n",
        "list_QA_split\n",
        "flat_list = [item for sublist in list_QA_split for item in sublist]\n",
        "# Contient les questions 10 à 38, alterne question et reponse\n",
        "\n",
        "tmp  = flat_list + [item for sublist in QA for item in sublist]\n",
        "ls = list(range(10,50))\n",
        "indice_question = 0\n",
        "for i in range(len(tmp)-1):\n",
        "  if(indice_question%2 == 0):\n",
        "    # C'est une question et doit donc contenir un nombre\n",
        "    if(str(ls[indice_question]) not in tmp[i]):\n",
        "      # Alors c'est une réponse \n",
        "      print(ls[indice_question])\n",
        "      print(tmp[i])\n",
        "      tmp[i-1] = tmp[i-1] + \" \" +  tmp[i]\n",
        "      tmp[i] =\"\"\n",
        "    else:\n",
        "      indice_question = indice_question + 1\n",
        "  else:\n",
        "    # C'est une réponse\n",
        "    # Recupère la valeur de la réponse dans la question\n",
        "    if( \"a)\" in tmp[i]):\n",
        "      first = tmp[i-1].split('a.')\n",
        "      second = first[-1].split('b.')\n",
        "      tmp[i] = tmp[i].replace(\"a)\", \"a)\" + second[0]+ \" \")    \n",
        "    elif( 'b)' in tmp[i]):\n",
        "      first = tmp[i-1].split('b.')\n",
        "      second = first[-1].split('c.')\n",
        "      tmp[i] = tmp[i].replace(\"b)\", \"b)\" + second[0]+ \" \")\n",
        "    elif( 'c)' in tmp[i]):\n",
        "      first = tmp[i-1].split('c.')\n",
        "      second = first[-1].split('d.')\n",
        "      tmp[i] = tmp[i].replace(\"c)\", \"c)\" + second[0]+ \" \")   \n",
        "    elif( 'd)' in tmp[i]):\n",
        "      first = tmp[i-1].split('d.')\n",
        "      second = first[-1]\n",
        "      tmp[i] = tmp[i].replace(\"d)\", \"d)\" + second+ \" \")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4FAbtQvanF5"
      },
      "source": [
        "# Insertion des questions réponses dans le dataframe\n",
        "# Seconde partie des questions\n",
        "cpt_df += 1\n",
        "for i in tmp:\n",
        "  try:\n",
        "    int(i[0])\n",
        "    cpt_df += 1\n",
        "    df['Question'].loc[cpt_df] = i\n",
        "  except:\n",
        "    df['Answer'].loc[cpt_df] = i\n",
        "\n",
        "# Première partie\n",
        "cpt_df += 1\n",
        "reponse=\"\"\n",
        "for l in range(len(QA)):\n",
        "  question=\"\"\n",
        "  try: \n",
        "    int(QA[l][0][0])\n",
        "  #Si ça ne commence pas par un numéro c'est une réponse\n",
        "  except:\n",
        "    reponse+=QA[l][0]\n",
        "    \n",
        "  else:\n",
        "    if (l != 0):\n",
        "      df['Answer'].loc[cpt_df] = reponse\n",
        "      reponse=\"\"\n",
        "    cpt_df += 1\n",
        "    question = QA[l][0].split('.')[1:]\n",
        "    q = question[0]\n",
        "    df['Question'].loc[cpt_df] = q\n",
        "\n",
        "df['Answer'].loc[cpt_df] = reponse\n",
        "\n",
        "# Efface les cellules vides - allocation à 200\n",
        "df = df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqrS1MEm-Ugm"
      },
      "source": [
        "On obtient un dataframe composé des questions et réponses de 3 différents sites. Il n'est pas nécéssaire de préprocess le texte puisque Bert s'en chargera par la suite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH7Hao_qSLXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7476e039-a5ad-4032-ca00-7db52a0cd041"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is NLP(natural language processing) ?</td>\n",
              "      <td>Natural language processing is a subfield of c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is applications of NLP ?</td>\n",
              "      <td>Text classification, Text summarization, Name ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is tokenization ?</td>\n",
              "      <td>Splitting the sentence into words</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is stemming ?</td>\n",
              "      <td>Stemming is the process of reducing a word to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is lemmatizing ?</td>\n",
              "      <td>Lemmatizing is also same like stemming but the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Which NLP model gives best accuracy?</td>\n",
              "      <td>Naive Bayes Algorithm has the highest accuracy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>What are the major tasks of NLP?</td>\n",
              "      <td>Translation, named entity recognition, relatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>What are stop words in NLP?</td>\n",
              "      <td>Common words that occur in sentences that add ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>What is stemming in NLP?</td>\n",
              "      <td>The process of obtaining the root word from th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>Why is NLP so hard?</td>\n",
              "      <td>There are several factors that make the proces...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>115 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       Question                                             Answer\n",
              "0    What is NLP(natural language processing) ?  Natural language processing is a subfield of c...\n",
              "1                 What is applications of NLP ?  Text classification, Text summarization, Name ...\n",
              "2                        What is tokenization ?                  Splitting the sentence into words\n",
              "3                           What is stemming ?   Stemming is the process of reducing a word to ...\n",
              "4                        What is lemmatizing ?   Lemmatizing is also same like stemming but the...\n",
              "..                                          ...                                                ...\n",
              "114        Which NLP model gives best accuracy?  Naive Bayes Algorithm has the highest accuracy...\n",
              "115            What are the major tasks of NLP?  Translation, named entity recognition, relatio...\n",
              "116                 What are stop words in NLP?  Common words that occur in sentences that add ...\n",
              "117                    What is stemming in NLP?  The process of obtaining the root word from th...\n",
              "118                         Why is NLP so hard?  There are several factors that make the proces...\n",
              "\n",
              "[115 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCvdT4CYV2UZ"
      },
      "source": [
        "## **Trie**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIji-wMXLGui"
      },
      "source": [
        "# Trie le dataframe dans l'ordre croissant de la taille des questions \n",
        "s = df.Answer.str.len().sort_values().index # Renvoie les indexes\n",
        "ds = df.reindex(s) # Recupère les indexes \n",
        "ds  = ds.reset_index() # Reset les indexes\n",
        "df = ds[:81] # Recupère une questions ayant les réponses les plus courtes pour un fonctionnement optimal de Bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CizCe4vkUliL"
      },
      "source": [
        "# **Bert**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u73fWkr6Umec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "2b81953b51684c3385d1e9e8fe856368",
            "55b2ee8bd53e41498aeb90f3b2b8d070",
            "8144c86b427f433bb677792d72cffee9",
            "134b4c4f33434af2848f19420f6a98ce",
            "e0a899c6c25c4a55935ee23b304a1d32",
            "66d72628c4dd4d05bcef18b798733c9b",
            "103a3d9ce0ab45f8826d27fe0fd1cf70",
            "5c577424951c4db6ba0d124cfcbcb2b6",
            "14907a1b2e3149a6ac2587b5e16c0c14",
            "c3b5513784ef4cdca049c402d1fd437d",
            "f7e5d782dfe241689afe4750f63e0979",
            "36d4404b9e05493d8b56874c6fbd3f2a",
            "5e19c6d371a2497d9b8e6bf4aba8a405",
            "f8d7f2a050fc4e619db073c9b571b4c6",
            "393564ff309c40cf8dce7254e29c57a4",
            "8edb0567ea6e4956a7c958786e98822f",
            "2d0e1c865fd24a69af2e8aa5e8050ae4",
            "3162846466684766bf6a408c869e15b9",
            "26bd67e6cdce400ea08f4db37f8bc284",
            "f4a4ca4a42224e8c8c775e79e94bcd58",
            "b74cbecdb89a4757a0c386274dfa4a48",
            "995a6740091642e19cc1ffa237ee4c71",
            "6cfad08028f64dcbbe8c23e23f56c1ee",
            "5e76c68f9bd147b895c5c5e8514bea5b"
          ]
        },
        "outputId": "94134058-83d4-4de7-da25-dffd6e7baa8d"
      },
      "source": [
        "#Model\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "\n",
        "#Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b81953b51684c3385d1e9e8fe856368",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14907a1b2e3149a6ac2587b5e16c0c14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d0e1c865fd24a69af2e8aa5e8050ae4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZDqUZ2GUpIn"
      },
      "source": [
        "#fonction permettant l'application de bert sur une question et une chaine de caractère contenant les réponses \n",
        "def bert(question,reponse):\n",
        "  encoding = tokenizer.encode_plus(text=question,text_pair=reponse, add_special=True)\n",
        "\n",
        "  inputs = encoding['input_ids']  #Token embeddings\n",
        "  sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
        "  tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens\n",
        "\n",
        "  x=model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
        "  start_index = torch.argmax(x[0])\n",
        "\n",
        "  end_index = torch.argmax(x[1])\n",
        "\n",
        "  answer = ' '.join(tokens[start_index:end_index+1])\n",
        "  \n",
        "  corrected_answer = ''\n",
        "\n",
        "  for word in answer.split():\n",
        "      \n",
        "      #If it's a subword token\n",
        "      if word[0:2] == '##':\n",
        "          corrected_answer += word[2:]\n",
        "      else:\n",
        "          corrected_answer += ' ' + word\n",
        "  return corrected_answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyEzLoTKrfGN"
      },
      "source": [
        "Pour utiliser Bert, on doit donner a notre modèle une question et une chaine de caractère contenant les réponses aux potentielles questions.\n",
        "\n",
        "Cepandant, Bert limite la quantité max de tokens de la liste de réponses à 512, nous empêchant de l'utiliser directement sur toutes nos réponses. On doit réaliser l'algorithme de Bert sur plusieurs subsets de réponses, plutôt que sur l'ensemble. \n",
        "\n",
        "On considérera par la suite l'ensemble des réponses retournées par Bert comme nouvel ensemble de réponses possible a notre question. On réalisera cette opération tant que la liste de réponses pottentielles est trop grande pour Bert."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq1HPWPcpPwK"
      },
      "source": [
        "#fonction permettant de diviser la listes de réponse via Bert en sous listes de tailles sufisament petites pour appliquer Bert dessus\n",
        "def reduc(reponseBertamodif):\n",
        "  i=0\n",
        "  reponses=[]\n",
        "  answer=''\n",
        "  while (i<len(reponseBertamodif)):\n",
        "    if (len(answer)<300 and ( len(reponseBertamodif[i]) + len(answer))<300 ):\n",
        "      try:\n",
        "        answer+=reponseBertamodif[i]\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    else:\n",
        "      reponses.append(answer)\n",
        "      answer=''\n",
        "      i-=1\n",
        "    i+=1\n",
        "    \n",
        "  return reponses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqvmV-UiYpQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e190ff9f-1f46-4269-9562-481f7e1b01c2"
      },
      "source": [
        "#Question à poser a notre algorithme :\n",
        "question = 'What is NLP '\n",
        "\n",
        "#On extrait les réponses du dataframe, que l'on enregistre sous forme de liste\n",
        "i=0\n",
        "reponses=[]\n",
        "answer=''\n",
        "while (i<len(df)):\n",
        "  if (len(answer)<300 and ( len(df['Answer'][i]) + len(answer))<300 ):\n",
        "    try:\n",
        "      answer+=df['Answer'][i]\n",
        "    except:\n",
        "      pass\n",
        "  else:\n",
        "    reponses.append(answer)\n",
        "    answer=''\n",
        "    i-=1\n",
        "  i+=1\n",
        "  \n",
        "#On obtient la variable reponse qui contient une liste de réponses de taille suffisament petite pour Bert\n",
        "#On réalise Bert sur toutes les sous listes de réponses\n",
        "reponseBert =''\n",
        "reponseBertTableau=[]\n",
        "for i in range(len(reponses)):\n",
        "  result = bert(question,reponses[i])+'.'\n",
        "  reponseBertTableau.append(result)\n",
        "  reponseBert+=result\n",
        "\n",
        "\n",
        "vermines = ['','.',',']\n",
        "#Tant que les différentes réponses via bert on une taille trop élevé pour utiliser l'algorithme une seule fois,\n",
        "#On redivise nos réponses en listes de réponses\n",
        "while len(reponseBert)>300 :\n",
        "  reponses = reduc(reponseBertTableau)\n",
        "  tmp=[]\n",
        "  reponseBert=''\n",
        "  for i in range(len(reponses)):\n",
        "    if (reponses[i] not in vermines):\n",
        "      result=bert(question,reponses[i])+'.'\n",
        "      reponseBert+=result\n",
        "      tmp.append(result)\n",
        "  reponseBertTableau=tmp\n",
        "\n",
        "finalAnswer = bert(question,reponseBert)\n",
        "print(question)\n",
        "print(finalAnswer)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n",
            "Keyword arguments {'add_special': True} not recognized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "What is NLP \n",
            " natural language processing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Y-mKFmisUqku",
        "outputId": "854ab398-5056-4c9e-9a86-31980f53588c"
      },
      "source": [
        "finalAnswer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' natural language processing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}